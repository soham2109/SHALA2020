{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"soham_naha_ML_Assignment2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RNGCt-t9hq7H"},"source":["# Assignment 2: **Machine learning with tree based models** "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AlmhCLRrfoG4"},"source":["In this assignment, you will work on the **Titanic** dataset and use machine learning to create a model that predicts which passengers survived the **Titanic** shipwreck. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ysVvT5atiUCf"},"source":["---\n","## About the dataset:\n","---\n","* The column named  `Survived` is the label and the remaining columns are features. \n","* The features can be described as given below:\n","  <table>\n","  <thead>\n","    <tr>\n","      <th>Variable</th>\n","      <th>Definition </th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>pclass</td>\n","      <td>Ticket class\t</td>\n","    </tr>\n","    <tr>\n","      <td>SibSp</td>\n","      <td>Number of siblings / spouses aboard the Titanic</td>\n","    </tr>\n","    <tr>\n","      <td>Parch</td>\n","      <td>Number of parents / children aboard the Titanic</td>\n","    </tr>\n","    <tr>\n","      <td>Ticket</td>\n","      <td>Ticket number</td>\n","    </tr>\n","    <tr>\n","      <td>Embarked</td>\n","      <td>Port of Embarkation: C = Cherbourg, Q = Queenstown, S = Southampton</td>\n","    </tr>\n","  </tbody>\n","</table> \t"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2XYBBIcKkXtu"},"source":["---\n","## Instructions\n","---\n","* Apply suitable data pre-processing techniques, if needed. \n","* Implement a few classifiers to create your model and compare the performance metrics by plotting the curves like roc_auc, confusion matrix, etc. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KE79bLl6iCx2","colab":{}},"source":["import pandas as pd \n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eoqpA6qmZ_JT","outputId":"6ecaa517-ed19-4ad1-8776-dc5c7549dd26","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1591074750128,"user_tz":-330,"elapsed":4240,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["titanic_data = pd.read_csv('titanic.csv')\n","titanic_data.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n","0            1         0       3  ...   7.2500   NaN         S\n","1            2         1       1  ...  71.2833   C85         C\n","2            3         1       3  ...   7.9250   NaN         S\n","3            4         1       1  ...  53.1000  C123         S\n","4            5         0       3  ...   8.0500   NaN         S\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WzDpMsWdiJUs","outputId":"250c5f35-e04d-4745-a19b-798caf5541b1","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1591074750132,"user_tz":-330,"elapsed":4232,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["titanic_data.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(891, 12)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PsDAl89fk56N","outputId":"2dfac373-0963-44ac-bfc7-206aec872b30","colab":{"base_uri":"https://localhost:8080/","height":243},"executionInfo":{"status":"ok","timestamp":1591074750135,"user_tz":-330,"elapsed":4223,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["print(titanic_data.isna().sum())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"46Tfj4y3cLYi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":243},"outputId":"7d58ed73-8e14-4daa-bebf-47cb57b02b48","executionInfo":{"status":"ok","timestamp":1591074751451,"user_tz":-330,"elapsed":5529,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["# Handling Missing Data by filling with the median value\n","from sklearn.impute import SimpleImputer\n","data = titanic_data.copy(deep=True)\n","imputer = SimpleImputer(strategy=\"most_frequent\")\n","data.iloc[:,:] = imputer.fit_transform(titanic_data)\n","print(data.isna().sum())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TO8BoT_ycLYt","colab_type":"code","colab":{}},"source":["labels = data.Survived\n","train = data.drop(columns=[\"Survived\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KcBzVy1kcLY0","colab_type":"text"},"source":["## Preprocessing the data "]},{"cell_type":"code","metadata":{"id":"W-nR2mrEcLY1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":278},"outputId":"96fc9b92-2ab5-4f71-a697-d9fa2e2d7035","executionInfo":{"status":"ok","timestamp":1591074751456,"user_tz":-330,"elapsed":5509,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["# Data conversion from objects and One-Hot Encoding\n","# converting Pclass\n","train[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\n","train = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pclass\")\n","train = pd.get_dummies(train, columns=[\"Embarked\"] , prefix=\"Embarked\")\n","\n","# converting Sex\n","train = pd.get_dummies(train,columns=[\"Sex\"])\n","train.drop(\"Sex_female\",axis=1)\n","\n","# Sibsp and Parch\n","train['Travelpeople']=train[\"SibSp\"]+train[\"Parch\"]\n","train['TravelAlone']=np.where(train['Travelpeople']>0, 0, 1)\n","\n","# Treating the names\n","train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\n","train['Title'] = train['Title'].replace([ 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona', 'Countess', 'Lady', 'Sir'], 'Rare')\n","train['Title'] = train['Title'].replace('Mlle', 'Miss')\n","train['Title'] = train['Title'].replace('Ms', 'Miss')\n","train['Title'] = train['Title'].replace('Mme', 'Mrs')\n","title = pd.get_dummies(train[\"Title\"])\n","train = pd.get_dummies(train,columns=[\"Title\"])\n","\n","# treating the names of people by arranginng them according to the lengths\n","train_name=train[\"Name\"]\n","for i in train['Name']:\n","    train['Name']= train['Name'].replace(i,len(i))\n","    \n","bins = [0,25,40, np.inf]\n","mylabels = ['s_name', 'm_name', 'l_name',]\n","train[\"Name_len\"] = pd.cut(train[\"Name\"], bins, labels = mylabels)\n","Name_mapping = {'s_name': 1, 'm_name': 2 , 'l_name': 3}\n","train['Name_len'] = train['Name_len'].map(Name_mapping)\n","\n","\n","# working with the age of passengers\n","bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\n","mylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n","train['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\n","age_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult':5 , 'Adult': 6, 'Senior':7}\n","train['AgeGroup'] = train['AgeGroup'].map(age_mapping)\n","\n","# Fare feature\n","train['FareBand'] = pd.qcut(train['Fare'], 8, labels = [1, 2, 3, 4,5,6,7,8])\n","\n","train = train.drop(columns=[\"Name\",\"SibSp\",\"Parch\",\"Travelpeople\"],axis=1)\n","\n","# preprocessing ticket to make sense\n","train['Ticket1']=train['Ticket'].str[:1]\n","train['Ticket1']=train['Ticket1'].replace(['1', '2', '3', '4', '5', '6', '7', '8', '9'], 'N')\n","train['Ticket1']=train['Ticket1'].replace(['S','P', 'C', 'N'], ['S_Ticket', 'P_Ticket', 'C_Ticket','NumberTicket'])\n","train['Ticket1']=train['Ticket1'].replace(['A','W', 'F', 'L'], 'OtherTicket')\n","\n","train = pd.get_dummies(train,columns=[\"Ticket1\"])\n","train.drop(\"Ticket\",inplace=True,axis=1)\n","train.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","      <th>Sex_female</th>\n","      <th>Sex_male</th>\n","      <th>TravelAlone</th>\n","      <th>Title_Master</th>\n","      <th>Title_Miss</th>\n","      <th>Title_Mr</th>\n","      <th>Title_Mrs</th>\n","      <th>Title_Rare</th>\n","      <th>Name_len</th>\n","      <th>AgeGroup</th>\n","      <th>FareBand</th>\n","      <th>Ticket1_C_Ticket</th>\n","      <th>Ticket1_NumberTicket</th>\n","      <th>Ticket1_OtherTicket</th>\n","      <th>Ticket1_P_Ticket</th>\n","      <th>Ticket1_S_Ticket</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>22.0</td>\n","      <td>7.2500</td>\n","      <td>B96 B98</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>38.0</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>26.0</td>\n","      <td>7.9250</td>\n","      <td>B96 B98</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>35.0</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>35.0</td>\n","      <td>8.0500</td>\n","      <td>B96 B98</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId   Age  ...  Ticket1_P_Ticket Ticket1_S_Ticket\n","0            1  22.0  ...                 0                0\n","1            2  38.0  ...                 1                0\n","2            3  26.0  ...                 0                1\n","3            4  35.0  ...                 0                0\n","4            5  35.0  ...                 0                0\n","\n","[5 rows x 26 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"ZcrW9PH0cLY8","colab_type":"text"},"source":["## Model development : Logistic Regression, Decision Tree and RandomForest"]},{"cell_type":"code","metadata":{"id":"oJit2PAxcLY9","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","train.drop(['PassengerId',\"Cabin\"], axis=1,inplace=True)\n","x_train, x_test, y_train, y_test = train_test_split(train, labels, test_size = 0.20, random_state = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_d2_e7acLZE","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","\n","logmodel = LogisticRegression(random_state= 0, solver='lbfgs', max_iter=10000,C=10)\n","logmodel.fit(x_train, y_train)\n","y_pred = logmodel.predict(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"psQfZZXocLZL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"5e35d5b3-d220-4426-8818-4fb8cce956c5","executionInfo":{"status":"ok","timestamp":1591074751463,"user_tz":-330,"elapsed":5490,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["from sklearn.metrics import roc_auc_score,confusion_matrix,classification_report\n","\n","print(\"ROC score : \\n\",roc_auc_score(y_test,y_pred))\n","print(\"Accuracy score : \\n\",accuracy_score(y_test,y_pred))\n","print(\"Confusion Matrix : \\n\",confusion_matrix(y_test,y_pred))\n","print(\"Precision and Recall : \\n\",classification_report(y_test,y_pred))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["ROC score : \n"," 0.7805006587615284\n","Accuracy score : \n"," 0.7932960893854749\n","Confusion Matrix : \n"," [[92 18]\n"," [19 50]]\n","Precision and Recall : \n","               precision    recall  f1-score   support\n","\n","           0       0.83      0.84      0.83       110\n","           1       0.74      0.72      0.73        69\n","\n","    accuracy                           0.79       179\n","   macro avg       0.78      0.78      0.78       179\n","weighted avg       0.79      0.79      0.79       179\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H3wntJljcLZU","colab_type":"code","colab":{}},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","dec_tree = DecisionTreeClassifier()\n","rf = RandomForestClassifier(n_estimators=1000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rv8lEeycLZb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"ad1c0ff8-11fa-4f36-a4f0-8e4d6e099c8d","executionInfo":{"status":"ok","timestamp":1591074752469,"user_tz":-330,"elapsed":6479,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["rf.fit(x_train, y_train)\n","y_pred = rf.predict(x_test)\n","print(\"ROC score : \\n\",roc_auc_score(y_test,y_pred))\n","print(\"Accuracy score : \\n\",accuracy_score(y_test,y_pred))\n","print(\"Confusion Matrix : \\n\",confusion_matrix(y_test,y_pred))\n","print(\"Precision and Recall : \\n\",classification_report(y_test,y_pred))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["ROC score : \n"," 0.7996706192358366\n","Accuracy score : \n"," 0.8268156424581006\n","Confusion Matrix : \n"," [[101   9]\n"," [ 22  47]]\n","Precision and Recall : \n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.92      0.87       110\n","           1       0.84      0.68      0.75        69\n","\n","    accuracy                           0.83       179\n","   macro avg       0.83      0.80      0.81       179\n","weighted avg       0.83      0.83      0.82       179\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_xEcc9gncLZj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":312},"outputId":"d94bf28a-39ed-44eb-b45c-9f89e69e5fe3","executionInfo":{"status":"ok","timestamp":1591074752472,"user_tz":-330,"elapsed":6476,"user":{"displayName":"Soham Naha","photoUrl":"","userId":"16336359137283689663"}}},"source":["dec_tree.fit(x_train, y_train)\n","y_pred = dec_tree.predict(x_test)\n","print(\"ROC score : \\n\",roc_auc_score(y_test,y_pred))\n","print(\"Accuracy score : \\n\",accuracy_score(y_test,y_pred))\n","print(\"Confusion Matrix : \\n\",confusion_matrix(y_test,y_pred))\n","print(\"Precision and Recall : \\n\",classification_report(y_test,y_pred))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["ROC score : \n"," 0.7823451910408431\n","Accuracy score : \n"," 0.7988826815642458\n","Confusion Matrix : \n"," [[94 16]\n"," [20 49]]\n","Precision and Recall : \n","               precision    recall  f1-score   support\n","\n","           0       0.82      0.85      0.84       110\n","           1       0.75      0.71      0.73        69\n","\n","    accuracy                           0.80       179\n","   macro avg       0.79      0.78      0.79       179\n","weighted avg       0.80      0.80      0.80       179\n","\n"],"name":"stdout"}]}]}